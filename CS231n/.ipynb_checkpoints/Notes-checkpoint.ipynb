{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation functions\n",
    "\n",
    "maybe I should document some of the different types of activation fucntion and include graphs, info about gradients, ... why?\n",
    "\n",
    "Examples\n",
    "\n",
    "* RELU\n",
    "* Leaky\n",
    "* Tanh\n",
    "* Sigmoid\n",
    "* Exp(-phi)\n",
    "* ?? Maxout, elu, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimisation update rules\n",
    "\n",
    "\n",
    "### Examples\n",
    "Stocastic grad descent\n",
    "Adagrad\n",
    "Momentum (Nesterov)\n",
    "RMSprop\n",
    "Adam\n",
    "\n",
    "Second order optimization methods ?!?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing data\n",
    "\n",
    "* Normalising\n",
    "* mean = 0\n",
    "* whitening\n",
    "* PCA\n",
    "\n",
    "\n",
    "Small data set. Make it bigger. Reverse images, translate, occlude, ... any thing to make it visually different but still in the same class. However, this would/could strengthen any biases present in your data? For example, imagine we dont have many pictures of cats. To the ones we have, we perturb the location, rotation, colors, ... but it turns out that 60% of our cat pics have a certain shape of ear. Thus, the added pics, from the same pool, will make the classifier more biased towards cats with that certain shape of ear???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interesting points\n",
    "\n",
    "* \"Make sure thatyou can overfit verysmall portion of the training data.\" ->This means that the net should have enough complexity to fit the data properly??\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions\n",
    "\n",
    "* l5 - p35 - mean 0, all positive input to a node???\n",
    "* l5 - p60 - decreasing stdev of weight. does this have any significance?\n",
    "* what does vanilla mean?!?\n",
    "* regularisation? definition?\n",
    "* what happened to normalisaton?\n",
    "* what is the difference between a 1D CNN and a RNN??? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
