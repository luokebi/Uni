{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from plotly.offline import iplot\n",
    "import plotly.graph_objs as go\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NBconvert - set all headings to add an id so i can link to them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Contents\n",
    "* [Motivation](#Motivation)\n",
    "* [Background](#Background)\n",
    "    * [Gaussians](#Gaussians)\n",
    "    * [KL divergence](#KL divergence)\n",
    "    * [Norms and metric spaces](#Norms)\n",
    "* [t - SNE](#tSNE)\n",
    "    * [Overview](#Overview)\n",
    "    * [Method](#Method)\n",
    "        * [Cost function](#Cost function)\n",
    "        * [Optimisers](#Optimisers)\n",
    "    * [Implementation](#Implementation)\n",
    "    * [Results](#Results)\n",
    "* [Questions](#Questions)\n",
    "* [References](#References)\n",
    "* [Glossary](#Glossary)\n",
    "\n",
    "\n",
    "\n",
    "# Motivation <a id='Motivation'></a>\n",
    "\n",
    "To efficiently ??? \n",
    "\n",
    "* Find topology of data? It would be nice to ?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Background <a id='Background'></a>\n",
    "\n",
    "### Perplexity and \n",
    "\n",
    "\n",
    "<span style=\"background-color: #FFFF00\">need to learn this</span>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussians <a id='Gaussians'></a>\n",
    "\n",
    "\n",
    " The \n",
    "$f\\left(x\\right) = a e^{- { \\frac{(x-b)^2 }{ 2 c^2} } }$\n",
    "\n",
    "Normalized Gaussian curves with expected value μ and variance $\\sigma^2$. The corresponding parameters are $a = \\tfrac{1}{\\sigma\\sqrt{2\\pi}}$, $b = \\mu$, and $c = \\sigma$.\n",
    "\n",
    "Therefore $f(x) = \\frac{1}{\\sigma \\sqrt{2\\pi}} e^{-\\frac{(x-\\mu)^{2}}{(2\\sigma)^2}}$\n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "\n",
    "```\n",
    "Am I sure that this is right? what is the $k \\neq i$ all about?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"3ad32ef5-f949-4444-b578-716d8a88d1a7\" style=\"height: 525; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"3ad32ef5-f949-4444-b578-716d8a88d1a7\", [{\"name\": \"Gaussian\", \"mode\": \"lines\", \"type\": \"scatter\", \"y\": [0.00044596855582147894, 0.0006072004282301823, 0.0008215322898142798, 0.00110454126257681, 0.0014757200892584108, 0.0019592541372638315, 0.002584891352997558, 0.0033888984338546206, 0.0044150898953665444, 0.005715908741131154, 0.007353528165027911, 0.009400933317355786, 0.011942930975789419, 0.015077023460175705, 0.01891407196213083, 0.023578664431138034, 0.029209095215833952, 0.03595685885779485, 0.043985559885870565, 0.053469145256268384, 0.06458937721738575, 0.07753248263421006, 0.09248494065786068, 0.109628404125551, 0.12913379076460862, 0.15115462710303892, 0.17581977928202772, 0.2032257584208417, 0.23342884092892865, 0.2664372928605482, 0.3022040284384758, 0.3406200625369202, 0.38150913170000395, 0.42462385514612905, 0.4696437839012756, 0.5161756414831566, 0.5637559934513361, 0.611856497087685, 0.6598917793915988, 0.7072298758031422, 0.7532050391989009, 0.7971326053090239, 0.8383254839405071, 0.8761117425521359, 0.9098526667237177, 0.9389606269168652, 0.9629160572853194, 0.9812828630345682, 0.9937216187678521, 1.0, 1.0, 0.9937216187678521, 0.9812828630345682, 0.9629160572853194, 0.9389606269168654, 0.9098526667237177, 0.8761117425521359, 0.8383254839405071, 0.7971326053090242, 0.7532050391989009, 0.7072298758031422, 0.6598917793915988, 0.6118564970876852, 0.5637559934513363, 0.5161756414831566, 0.4696437839012756, 0.4246238551461289, 0.3815091317000041, 0.34062006253692023, 0.3022040284384758, 0.2664372928605482, 0.2334288409289288, 0.2032257584208418, 0.17581977928202772, 0.15115462710303892, 0.12913379076460874, 0.1096284041255511, 0.09248494065786068, 0.07753248263421006, 0.0645893772173858, 0.05346914525626834, 0.043985559885870565, 0.0359568588577949, 0.029209095215833952, 0.023578664431138055, 0.018914071962130786, 0.015077023460175705, 0.011942930975789441, 0.009400933317355779, 0.007353528165027911, 0.00571590874113117, 0.0044150898953665444, 0.0033888984338546284, 0.0025848913529975515, 0.0019592541372638315, 0.001475720089258415, 0.00110454126257681, 0.0008215322898142798, 0.0006072004282301807, 0.00044596855582147894], \"x\": [-10.0, -9.899497487437186, -9.798994974874372, -9.698492462311558, -9.597989949748744, -9.49748743718593, -9.396984924623116, -9.296482412060302, -9.195979899497488, -9.095477386934673, -8.99497487437186, -8.894472361809045, -8.793969849246231, -8.693467336683417, -8.592964824120603, -8.492462311557789, -8.391959798994975, -8.291457286432161, -8.190954773869347, -8.090452261306533, -7.989949748743719, -7.889447236180905, -7.788944723618091, -7.688442211055277, -7.5879396984924625, -7.4874371859296485, -7.386934673366834, -7.28643216080402, -7.185929648241206, -7.085427135678392, -6.984924623115578, -6.884422110552764, -6.78391959798995, -6.683417085427136, -6.582914572864322, -6.482412060301508, -6.381909547738694, -6.28140703517588, -6.180904522613066, -6.080402010050252, -5.979899497487437, -5.879396984924623, -5.7788944723618085, -5.6783919597989945, -5.57788944723618, -5.477386934673366, -5.376884422110552, -5.276381909547738, -5.175879396984924, -5.07537688442211, -4.974874371859296, -4.874371859296482, -4.773869346733668, -4.673366834170854, -4.57286432160804, -4.472361809045226, -4.371859296482412, -4.271356783919598, -4.1708542713567835, -4.0703517587939695, -3.9698492462311554, -3.8693467336683414, -3.7688442211055273, -3.6683417085427132, -3.567839195979899, -3.467336683417085, -3.366834170854271, -3.266331658291457, -3.165829145728643, -3.065326633165829, -2.964824120603015, -2.8643216080402008, -2.7638190954773867, -2.6633165829145726, -2.5628140703517586, -2.4623115577889445, -2.3618090452261304, -2.2613065326633164, -2.1608040201005023, -2.0603015075376883, -1.9597989949748733, -1.8592964824120592, -1.7587939698492452, -1.6582914572864311, -1.557788944723617, -1.457286432160803, -1.356783919597989, -1.2562814070351749, -1.1557788944723608, -1.0552763819095468, -0.9547738693467327, -0.8542713567839186, -0.7537688442211046, -0.6532663316582905, -0.5527638190954764, -0.4522613065326624, -0.3517587939698483, -0.25125628140703427, -0.1507537688442202, -0.05025125628140614, 0.05025125628140792, 0.15075376884422198, 0.25125628140703604, 0.3517587939698501, 0.45226130653266416, 0.5527638190954782, 0.6532663316582923, 0.7537688442211063, 0.8542713567839204, 0.9547738693467345, 1.0552763819095485, 1.1557788944723626, 1.2562814070351767, 1.3567839195979907, 1.4572864321608048, 1.5577889447236188, 1.658291457286433, 1.758793969849247, 1.859296482412061, 1.959798994974875, 2.060301507537689, 2.160804020100503, 2.2613065326633173, 2.3618090452261313, 2.4623115577889454, 2.5628140703517595, 2.6633165829145735, 2.7638190954773876, 2.8643216080402016, 2.9648241206030157, 3.0653266331658298, 3.165829145728644, 3.266331658291458, 3.366834170854272, 3.467336683417086, 3.5678391959799, 3.668341708542714, 3.768844221105528, 3.8693467336683423, 3.9698492462311563, 4.07035175879397, 4.170854271356784, 4.2713567839195985, 4.371859296482413, 4.472361809045227, 4.572864321608041, 4.673366834170855, 4.773869346733669, 4.874371859296483, 4.974874371859297, 5.075376884422111, 5.175879396984925, 5.276381909547739, 5.376884422110553, 5.477386934673367, 5.577889447236181, 5.678391959798995, 5.778894472361809, 5.8793969849246235, 5.9798994974874375, 6.080402010050253, 6.180904522613066, 6.2814070351758815, 6.381909547738694, 6.48241206030151, 6.582914572864322, 6.683417085427138, 6.78391959798995, 6.884422110552766, 6.984924623115578, 7.085427135678394, 7.185929648241206, 7.286432160804022, 7.386934673366834, 7.48743718592965, 7.5879396984924625, 7.688442211055278, 7.788944723618091, 7.8894472361809065, 7.989949748743719, 8.090452261306535, 8.190954773869347, 8.291457286432163, 8.391959798994975, 8.49246231155779, 8.592964824120603, 8.693467336683419, 8.793969849246231, 8.894472361809047, 8.99497487437186, 9.095477386934675, 9.195979899497488, 9.296482412060303, 9.396984924623116, 9.497487437185931, 9.597989949748744, 9.69849246231156, 9.798994974874372, 9.899497487437188, 10.0]}, {\"name\": \"Softmaxed gaussian\", \"mode\": \"lines\", \"type\": \"scatter\", \"y\": [0.0004457044303278329, 0.0005200750410201016, 0.0006059099896359434, 0.0007048119409880788, 0.0008185805732798305, 0.0009492326192143659, 0.0010990233351137453, 0.0012704694121450828, 0.0014663733290790368, 0.001689849129002331, 0.0019443495829578378, 0.002233694681502829, 0.002562101370596468, 0.002934214421023838, 0.003355138290747178, 0.0038304698072030145, 0.004366331461744118, 0.0049694050713233705, 0.0056469655233584316, 0.006406914278795792, 0.007257812266074119, 0.008208911755408428, 0.009270186759092547, 0.010452361459941037, 0.01176693612723078, 0.01322620993830324, 0.014843300085165509, 0.016632156509865048, 0.018607571581049996, 0.02078518399795326, 0.02318147618808178, 0.02581376445220107, 0.028700181105836782, 0.03185964787151226, 0.035311839791319445, 0.03907713895613656, 0.04317657738674164, 0.04763176845400797, 0.05246482629095473, 0.057698272729165674, 0.06335493138630119, 0.06945780864023025, 0.0760299613485966, 0.08309435131004252, 0.09067368661423578, 0.09879025019136692, 0.1074657160467179, 0.11672095385075573, 0.12657582274818185, 0.13704895544838502, 0.14815753386242883, 0.15991705775541618, 0.17234110808492753, 0.1854411068931349, 0.19922607580887183, 0.21370239539299582, 0.2288735677223155, 0.2447399847506761, 0.2612987051070037, 0.2785432420858407, 0.296463365652932, 0.3150449213237726, 0.3342696687740137, 0.35411514300495034, 0.3745545408130952, 0.395556635198718, 0.4170857201933713, 0.43910158839061963, 0.46155954322785675, 0.48441044779134346, 0.5076008116032095, 0.531072916500616, 0.5547649823367737, 0.5786113728248674, 0.6025428414136873, 0.6264868166329434, 0.6503677258824856, 0.6741073561690177, 0.6976252498228107, 0.7208391327621101, 0.74366537242125, 0.7660194620268741, 0.7878165275019804, 0.8089718529064186, 0.8294014199913617, 0.8490224571600626, 0.8677539928933002, 0.8855174085200407, 0.9022369850959783, 0.917840439097902, 0.9322594416524805, 0.9454301160953106, 0.957293508800137, 0.9677960284282177, 0.9768898490219773, 0.9845332727024786, 0.9906910481229139, 0.9953346412754426, 0.9984424557405326, 1.0, 1.0, 0.9984424557405326, 0.9953346412754426, 0.9906910481229138, 0.9845332727024785, 0.9768898490219772, 0.9677960284282174, 0.9572935088001367, 0.9454301160953104, 0.9322594416524803, 0.9178404390979017, 0.9022369850959779, 0.8855174085200403, 0.8677539928932999, 0.8490224571600623, 0.8294014199913613, 0.8089718529064183, 0.78781652750198, 0.7660194620268738, 0.7436653724212496, 0.7208391327621099, 0.6976252498228105, 0.6741073561690175, 0.6503677258824854, 0.6264868166329431, 0.6025428414136871, 0.5786113728248672, 0.5547649823367735, 0.5310729165006158, 0.5076008116032092, 0.48441044779134335, 0.4615595432278566, 0.43910158839061947, 0.4170857201933712, 0.3955566351987178, 0.374554540813095, 0.3541151430049502, 0.3342696687740135, 0.3150449213237724, 0.2964633656529319, 0.27854324208584047, 0.26129870510700354, 0.24473998475067588, 0.22887356772231532, 0.2137023953929957, 0.19922607580887175, 0.1854411068931348, 0.17234110808492745, 0.15991705775541612, 0.14815753386242875, 0.13704895544838494, 0.12657582274818174, 0.11672095385075562, 0.1074657160467178, 0.09879025019136684, 0.0906736866142357, 0.08309435131004247, 0.07602996134859653, 0.0694578086402302, 0.0633549313863011, 0.05769827272916557, 0.05246482629095473, 0.047631768454007885, 0.04317657738674164, 0.03907713895613647, 0.035311839791319445, 0.031859647871512194, 0.028700181105836782, 0.025813764452201012, 0.02318147618808178, 0.020785183997953233, 0.018607571581049996, 0.016632156509865017, 0.014843300085165509, 0.013226209938303216, 0.01176693612723078, 0.01045236145994102, 0.009270186759092547, 0.008208911755408405, 0.007257812266074119, 0.006406914278795775, 0.0056469655233584316, 0.004969405071323358, 0.004366331461744118, 0.003830469807203004, 0.003355138290747178, 0.0029342144210238274, 0.002562101370596468, 0.0022336946815028234, 0.0019443495829578378, 0.0016898491290023266, 0.0014663733290790368, 0.0012704694121450795, 0.0010990233351137453, 0.0009492326192143634, 0.0008185805732798305, 0.0007048119409880763, 0.0006059099896359434, 0.0005200750410200998, 0.0004457044303278329], \"x\": [-10.0, -9.899497487437186, -9.798994974874372, -9.698492462311558, -9.597989949748744, -9.49748743718593, -9.396984924623116, -9.296482412060302, -9.195979899497488, -9.095477386934673, -8.99497487437186, -8.894472361809045, -8.793969849246231, -8.693467336683417, -8.592964824120603, -8.492462311557789, -8.391959798994975, -8.291457286432161, -8.190954773869347, -8.090452261306533, -7.989949748743719, -7.889447236180905, -7.788944723618091, -7.688442211055277, -7.5879396984924625, -7.4874371859296485, -7.386934673366834, -7.28643216080402, -7.185929648241206, -7.085427135678392, -6.984924623115578, -6.884422110552764, -6.78391959798995, -6.683417085427136, -6.582914572864322, -6.482412060301508, -6.381909547738694, -6.28140703517588, -6.180904522613066, -6.080402010050252, -5.979899497487437, -5.879396984924623, -5.7788944723618085, -5.6783919597989945, -5.57788944723618, -5.477386934673366, -5.376884422110552, -5.276381909547738, -5.175879396984924, -5.07537688442211, -4.974874371859296, -4.874371859296482, -4.773869346733668, -4.673366834170854, -4.57286432160804, -4.472361809045226, -4.371859296482412, -4.271356783919598, -4.1708542713567835, -4.0703517587939695, -3.9698492462311554, -3.8693467336683414, -3.7688442211055273, -3.6683417085427132, -3.567839195979899, -3.467336683417085, -3.366834170854271, -3.266331658291457, -3.165829145728643, -3.065326633165829, -2.964824120603015, -2.8643216080402008, -2.7638190954773867, -2.6633165829145726, -2.5628140703517586, -2.4623115577889445, -2.3618090452261304, -2.2613065326633164, -2.1608040201005023, -2.0603015075376883, -1.9597989949748733, -1.8592964824120592, -1.7587939698492452, -1.6582914572864311, -1.557788944723617, -1.457286432160803, -1.356783919597989, -1.2562814070351749, -1.1557788944723608, -1.0552763819095468, -0.9547738693467327, -0.8542713567839186, -0.7537688442211046, -0.6532663316582905, -0.5527638190954764, -0.4522613065326624, -0.3517587939698483, -0.25125628140703427, -0.1507537688442202, -0.05025125628140614, 0.05025125628140792, 0.15075376884422198, 0.25125628140703604, 0.3517587939698501, 0.45226130653266416, 0.5527638190954782, 0.6532663316582923, 0.7537688442211063, 0.8542713567839204, 0.9547738693467345, 1.0552763819095485, 1.1557788944723626, 1.2562814070351767, 1.3567839195979907, 1.4572864321608048, 1.5577889447236188, 1.658291457286433, 1.758793969849247, 1.859296482412061, 1.959798994974875, 2.060301507537689, 2.160804020100503, 2.2613065326633173, 2.3618090452261313, 2.4623115577889454, 2.5628140703517595, 2.6633165829145735, 2.7638190954773876, 2.8643216080402016, 2.9648241206030157, 3.0653266331658298, 3.165829145728644, 3.266331658291458, 3.366834170854272, 3.467336683417086, 3.5678391959799, 3.668341708542714, 3.768844221105528, 3.8693467336683423, 3.9698492462311563, 4.07035175879397, 4.170854271356784, 4.2713567839195985, 4.371859296482413, 4.472361809045227, 4.572864321608041, 4.673366834170855, 4.773869346733669, 4.874371859296483, 4.974874371859297, 5.075376884422111, 5.175879396984925, 5.276381909547739, 5.376884422110553, 5.477386934673367, 5.577889447236181, 5.678391959798995, 5.778894472361809, 5.8793969849246235, 5.9798994974874375, 6.080402010050253, 6.180904522613066, 6.2814070351758815, 6.381909547738694, 6.48241206030151, 6.582914572864322, 6.683417085427138, 6.78391959798995, 6.884422110552766, 6.984924623115578, 7.085427135678394, 7.185929648241206, 7.286432160804022, 7.386934673366834, 7.48743718592965, 7.5879396984924625, 7.688442211055278, 7.788944723618091, 7.8894472361809065, 7.989949748743719, 8.090452261306535, 8.190954773869347, 8.291457286432163, 8.391959798994975, 8.49246231155779, 8.592964824120603, 8.693467336683419, 8.793969849246231, 8.894472361809047, 8.99497487437186, 9.095477386934675, 9.195979899497488, 9.296482412060303, 9.396984924623116, 9.497487437185931, 9.597989949748744, 9.69849246231156, 9.798994974874372, 9.899497487437188, 10.0]}], {}, {\"linkText\": \"Export to plot.ly\", \"showLink\": true})</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def Gaussian_plotter(sigma):\n",
    "    mu = 0\n",
    "    X = np.linspace(-10,10,200)\n",
    "    \n",
    "    Y = (1/sigma*np.sqrt(2*np.pi)) * np.exp(-((x - mu)**2)/((2*sigma)**2))\n",
    "    trace1 = go.Scatter(\n",
    "    x = X,\n",
    "    y = Y/np.max(Y),\n",
    "    mode = 'lines',\n",
    "    name = 'Gaussian')\n",
    "    \n",
    "    \n",
    "    Y = np.exp(-((X - 0)**2)/((2*sigma)**2))\n",
    "    Y = Y/(np.sum(Y))\n",
    "    trace2 = go.Scatter(\n",
    "    x = X,\n",
    "    y = Y/np.max(Y), \n",
    "    mode = 'lines',\n",
    "    name = 'Softmaxed gaussian')\n",
    "    iplot([trace1,trace2])\n",
    "widgets.interactive(Gaussian_plotter, sigma=(0.1,3))\n",
    "#normalised both plots so we could compare them - couldnt be bothered figuring out how to plot on different axes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So how does this relate to t-SNE?\n",
    "* This is the distribution that the probabilities are taken from. \n",
    "* High variance preserves global structure and low variance preserves local structure\n",
    "\t* hmm, it would be nice if we could avoid this dichotomy\n",
    "* Preferable we would have a distrubution with a long tail? this could help preserve global structure as the sum of all forces over the data points would help shape this\n",
    "\t* however, doesnt t-SNE repel some datapoints? need to look into this\n",
    "*  Why gaussians? It seems like a big assumption that the relationship between data points is gaussian.\n",
    "\t* What other options are there? \n",
    "\t* Gaussians give us? p(x), and symmetry. chi squared is more like two interacting forces? \n",
    "\n",
    "\n",
    "\n",
    "$p_{j\\mid i} = \\frac{\\exp(-\\lVert\\mathbf{x}_i - \\mathbf{x}_j\\rVert^2 / 2\\sigma_i^2)}{\\sum_{k \\neq i} \\exp(-\\lVert\\mathbf{x}_i - \\mathbf{x}_k\\rVert^2 / 2\\sigma_i^2)}$\n",
    "\n",
    "Hmm, that looks familiar.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kullback–Leibler divergence <a id='KL divergence'></a>\n",
    "\n",
    "It is also called the relative entropy of P with respect to Q, and written H(P|Q).\n",
    "\n",
    "$$D_{\\mathrm{KL}}(P\\|Q) = \\sum_i P(i) \\, \\log\\frac{P(i)}{Q(i)}$$\n",
    "\n",
    "Pictures to explain would be good\n",
    "\n",
    "Entropy is defined for a distrete random variable as the amount of information the expected value gives. (i think)\n",
    "\n",
    "$$ H (X) = \\sum_{i=1}^n {\\mathrm{P}(x_i)\\,\\mathrm{I}(x_i)} = -\\sum_{i=1}^n {\\mathrm{P}(x_i) \\log_b \\mathrm{P}(x_i)} $$\n",
    "\n",
    "Thus, KL divergence is\n",
    "\n",
    "$$ D_{\\mathrm{KL}}(P\\|Q) =  \\sum_i P(i) \\,( \\log P(i) -  \\log Q(i)) = \\sum_i P(i) \\, \\log\\frac{P(i)}{Q(i)}$$\n",
    "\n",
    "which says. The KL divergence is the difference in total entropy of each variable. no it isnt... (how does this relate to t-SNE and dimensionality reduction?)\n",
    "What does $ P(i) \\log(Q(i)) $ mean? The porbability of p times the information content of q.. ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# a surf plot would be good here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance, metrics and norms\n",
    "\n",
    "If we consider a simple example in 3d. We have two points, A and B. A = (3,4,10000) and B = (3,4,0). Now these two points are quite similar, except for the third dimension, z. If we took the euclidean distance between them it would equal\n",
    "\n",
    "which is not representative of their similairty. We needa better norm? What are the alternatives and how do we want it to behave?\n",
    "\n",
    "So we need a norm and a distrubution that some how work together to capture the global and/or local structre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9995.0012499999211"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(3**2 + 4**2 + 10000**2) - np.sqrt(3**2 + 4**2 + 0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "\n",
    "# t - SNE <a id='tSNE'></a>\n",
    "\n",
    "## Definition <a id='Definition'></a>\n",
    "\n",
    "Given a dataset of N high-dimensional objects $\\mathbf{x}_1, \\dots, \\mathbf{x}_N \\in \\mathbb{X}$, t-SNE first computes probabilities $p_{ij}$ that are proportional to the similarity of objects $\\mathbf{x}_i$ and $\\mathbf{x}_j$, as follows:\n",
    "\n",
    "$$p_{j\\mid i} = \\frac{\\exp(-\\lVert\\mathbf{x}_i - \\mathbf{x}_j\\rVert^2 / 2\\sigma_i^2)}{\\sum_{k \\neq i} \\exp(-\\lVert\\mathbf{x}_i - \\mathbf{x}_k\\rVert^2 / 2\\sigma_i^2)} \\\\\n",
    "p_{ij} = \\frac{p_{j\\mid i} + p_{i\\mid j}}{2N}$$\n",
    "The bandwidth of the Gaussian kernels $\\sigma_i$, is set in such a way that the perplexity of the conditional distribution equals a predefined perplexity using a binary search. As a result, the bandwidth is adapted to the density of the data: smaller values of \\sigma_i are used in denser parts of the data space.\n",
    "\n",
    "t-SNE aims to learn a d-dimensional map $\\mathbf{y}_1, \\dots, \\mathbf{y}_N$ (with $\\mathbf{y}_i \\in \\mathbb{R}^d$) that reflects the similarities $p_{ij}$ as well as possible. To this end, it measures similarities $q_{ij}$ between two points in the map $\\mathbf{y}_i$ and $\\mathbf{y}_j$, using a very similar approach. Specifically, $q_{ij}$ is defined as:\n",
    "\n",
    "$$q_{ij} = \\frac{(1 + \\lVert \\mathbf{y}_i - \\mathbf{y}_j\\rVert^2)^{-1}}{\\sum_{k \\neq \\ell} (1 + \\lVert \\mathbf{y}_k - \\mathbf{y}_\\ell\\rVert^2)^{-1}}$$\n",
    "Herein a heavy-tailed Student-t distribution is used to measure similarities between low-dimensional points in order to allow dissimilar objects to be modeled far apart in the map.\n",
    "\n",
    "The locations of the points \\mathbf{y}_i in the map are determined by minimizing the (non-symmetric) Kullback–Leibler divergence of the distribution Q from the distribution P, that is:\n",
    "\n",
    "$$ KL(P||Q) = \\sum_{i \\neq j} p_{ij} \\log \\frac{p_{ij}}{q_{ij}} $$\n",
    "The minimization of the Kullback–Leibler divergence with respect to the points $\\mathbf{y}_i$ is performed using gradient descent. The result of this optimization is a map that reflects the similarities between the high-dimensional inputs well.\n",
    "\n",
    "\n",
    "\n",
    "## Method <a id='Method'></a>\n",
    "\n",
    "\n",
    "\n",
    "### Cost function <a id='Cost function'></a>\n",
    "\n",
    "The cost function and derivates - <span style=\"background-color: #FFFF00\">need to derive this here!</span>\n",
    "\n",
    "$$ \\mathbf{C} = \\sum_{i} KL(P_i||Q_i) = \\sum_{i}\\sum_{j} p_{ij} \\log \\frac{p_{ij}}{q_{ij}} $$\n",
    "$$\\frac{\\partial \\mathbf{C}}{\\partial \\mathbf{y}} = 2 \\sum_{j} (\\mathbf{y}_i - \\mathbf{y}_j) (p_{ij} - q_{ij}  + p_{ji} - q_{ji})$$\n",
    "\n",
    "### Optimisers <a id='Optimisers'></a>\n",
    "\n",
    "So why does steepest descent not work? it has no way to get past local minima (a picture of the many local minima would be nice). Momentum and annealing (random jitter) help bump the \n",
    "\n",
    "Like a rock rolling down a hill. The problem with steepest gradient descent is that <s>the gradients are too low and</s> there are too many ledges and bluffs to get caught on. It will instantly stop, regardless of momentum, on any of these. ...  Momentum work better sa it will continue on throughSo as soon as it \n",
    "\n",
    "So I guess the questions this raises are;\n",
    "\n",
    "* how can we find the global maximum?\n",
    "* how can we get out of local minima? / \n",
    "    * random jumps, \n",
    "    * tunnel, \n",
    "    * use the history of the trajectory (momentum/integral control), \n",
    "* what are the best methods for optimising surfaces with many local minima? (surely whatever the solution it will be expensive?\n",
    "    * is this the sort of thing particle swarms are good at?\n",
    "* how can we reduce the amount of local minima in/on the surface?\n",
    "\n",
    "    \n",
    "    \n",
    "<span style=\"background-color: #FFFF00\">Need to learn how adagrad, adam, ... </span>\n",
    "\n",
    "## Implementation <a id='Implementation'></a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results and experiments <a id='Results'></a>\n",
    "\n",
    "To test\n",
    "* what happens if you init all y at the same position?\n",
    "* limits as gaussian width tends to 0 and inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " \n",
    "# Questions and thoughts<a id='Questions'></a>\n",
    "\n",
    "* The two functions to find p and q should be the same??\n",
    "* Slower rate of dimensionalty reduction, discrete, continuious. (reminds me of a recursive function?)\n",
    "* What if the data set is not a bunch of vectors, but matrixies, or other data structures??\n",
    "* The method needs to reflect the data somehow?\n",
    "* Are we only allowing orthogonal dimensions? This seems to be quite limiting?? For example, what if we could have dimensions that are curves? So MNIST would be a small number of curve dimensions??\n",
    "    * so what if we mapped it into non-euclidean grometry and then back? \n",
    "        * for example - images: we could mapp the pixel intensities into a line segments/curves and them back to a 2d position vector?\n",
    "        * into the number of turns greater that 270 degrees, then back to a 2d position vector?\n",
    "    * is this naturally what auto encoders do?\n",
    "    * what is the difference between a dimension and a feature?\n",
    "* what is this like? electro magnetic forces acting on particles? gravity acting on particles, a network of forces? ... what techinques have they developed?\n",
    "* data visualisation technique researchers dont seem to know exactally what they are looking to visualise. we need to rigorously define what it is we are trying to do\n",
    "* how does this work for unsupervised data? \n",
    "    * supervised data can ... nice visualisations? \n",
    "    * unsupervised? we are clustering based on similarities? we can look at how it has group datapoints and see the patterns?\n",
    "* why euclidean space and linear embeddings? it just seems these are convinient as the math is easy not because they are necessarily well suited to the problem\n",
    "* Surely for MNSIT we are uninterested at the lowest level of local structure? As pixels are normally next to other pixels, we already know this... We are interested in what groups of pixels correlate with others?? \n",
    "* The problem is there are many interpretations of similarity, and where do we draw the line? \n",
    "\t* Also, similaity in which dimensions, are they all created equal (is this what PCA does?)\n",
    "\n",
    "\n",
    "# Resources and references <a id='References'></a>\n",
    "\n",
    "* [t-SNE on SciKit learn](http://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html \"SciKit learn\")\n",
    "* [LAURENS VAN DER MAATEN](https://lvdmaaten.github.io/tsne/)\n",
    "* \n",
    "\n",
    "# Glossary <a id='Glossary'></a>\n",
    "\n",
    "* Local structure: the similarities/differences of \n",
    "* Global structure: the "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
